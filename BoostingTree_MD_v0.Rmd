---
title: "Boosting Tree and Package"
author: '[Gireg Willame](g.willame@detralytics.eu)'
date: '2023-03-15'
output:
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
  pdf_document:
    toc: yes
institute: Detralytics
---

# Introduction and database descriptive analysis

## Import libraries and database

Let's start by importing all the needed packages as well as the database of interest.
All the example will be designed on *freMTPLfreq* from `CASdatasets`.

```{r, results='hide', message=FALSE, warning=FALSE}
library(formatR)
library(CASdatasets)
library(ggplot2)
library(dplyr)
library(scales)
library(caret)
library(reshape2)

library(rpart)
library(rpart.plot)
library(gbm3)
library(BT)

data("freMTPLfreq")
db <- freMTPLfreq ; rm(freMTPLfreq)
```

Let's first have a look to the database.

```{r, tidy=TRUE}
str(db)
head(db)
```

One can also perform a quick summary.

```{r, tidy=TRUE}
summary(db)
sum(db[db$CarAge>25, "Exposure"])/sum(db$Exposure)
```

We therefore note that:

* Some records have an exposure > 1 year.
* The `Exposure` related to `CarAge` older than 25y.o. is quite limited.
It's seems natural to drop these specific records.
```{r, tidy=TRUE}
db <- db[db$Exposure<=1 & db$CarAge<=25,]
```

## Descriptive Analysis

One can now have a quick look to the univariate analysis for each variable.

### `ClaimNb`

```{r, fig.align='center', tidy=TRUE}
pctFormat <- scales::percent_format(accuracy = .1)
ggplot(db, aes(x=ClaimNb)) +
  geom_bar(alpha=.5) +
  geom_label(aes(label = sprintf('%s', pctFormat(..count../sum(..count..)))), stat='count', nudge_y = .2, size = 3)  + 
  theme_minimal() +
  xlab("Number of Claims") +
  ylab("Number of Policies")
```

### `Exposure`

Let's look into the `Exposure` distribution. In order to ease the representation, one can cut the variable in months.

```{r, fig.align='center', tidy=TRUE}
temp <- data.frame('Exposure'=cut(db$Exposure, 1/12*seq(0, 12, 1), labels=FALSE))
ggplot(temp, aes(x=factor(Exposure))) +
  geom_bar(alpha=.5) +
  geom_label(aes(label = sprintf('%s', pctFormat(..count../sum(..count..)))), stat='count', nudge_y = .2, size = 3)  + 
  theme_minimal() +
  xlab("Monthly Exposure") +
  ylab("Number of Policies")
```

One can also note that the global average claim frequency is around 7.01\%.

```{r, tidy=TRUE}
sum(db$ClaimNb)/sum(db$Exposure)
```

### Categorical features

We can create a short function that will generate a graph for all the categorical features.

```{r}
plotCatFunc <- function(db, feature, axisScale = 10, dodge=F){
  temp <- db %>% 
    group_by_at(feature) %>% 
    summarize(Exposure = sum(Exposure), ClaimNb = sum(ClaimNb)) %>% 
    mutate(AvgClaim = ClaimNb/Exposure, contFeature = as.numeric(.data[[feature]]), ExpoPct = pctFormat(Exposure/sum(Exposure)))
  p <- ggplot(temp) +
    geom_bar(aes_string(x=feature, y = "Exposure"), stat="identity", alpha=.5) +
    geom_label(aes_string(x=feature, y="Exposure", label="ExpoPct"), nudge_y = .2, size = 3) + 
    geom_line(aes(x=contFeature, y = ClaimNb/Exposure * axisScale * max(Exposure))) +
    scale_y_continuous("Exposure", sec.axis = sec_axis(~./(max(temp$Exposure)*axisScale), name = "Average # of claims")) +
    {if (dodge)scale_x_discrete(guide = guide_axis(n.dodge = 2))} +
    theme_minimal() +
    xlab(feature)
  return(p)
}
```

We can now loop across all categorical features.

```{r, fig.align='center', tidy=TRUE}
whichCat <- setdiff(names(db)[sapply(db, is.factor)], 'PolicyID')
for (varGraph in whichCat){
  print(plotCatFunc(db, varGraph, dodge=varGraph %in% c('Region', 'Brand')))
}
```


### Continuous features

We can now focus on the continuous features. The idea will be to adequately bin them and use the previous function to plot.

```{r, tidy=TRUE}
whichCont <- setdiff(setdiff(names(db), whichCat), c('PolicyID', 'ClaimNb', 'Exposure'))
temp <- data.frame('CarAgeBin' = as.factor(db$CarAge),
                   'DriverAgeBin' = cut(db$DriverAge, breaks=c(min(db$DriverAge), seq(25, max(db$DriverAge)+1, 5)), include.lowest = TRUE),
                   'DensityBin' = as.factor(cut(db$Density, breaks=c(seq(0,90,10), seq(100, 900, 100), seq(1000, max(db$Density), 1000)), include.lowest = TRUE, labels=FALSE)))
temp <- cbind(temp, 'ClaimNb'=db$ClaimNb, 'Exposure'=db$Exposure)
```

```{r, fig.align='center', tidy=TRUE}
scalingValues <- list('CarAge'=10, 'DriverAge'=10, 'Density'=5)
for (varGraph in whichCont){
  print(plotCatFunc(temp, paste0(varGraph, "Bin"), axisScale=scalingValues[[varGraph]], dodge=!(varGraph=='CarAge')))
}
```

What if one rely on quantiles to perform the binning ?

```{r, tidy=TRUE}
temp <- data.frame('CarAgeBin' = cut(db$CarAge, breaks=quantile(db$CarAge, seq(0, 1, 0.1)), include.lowest=TRUE),
                   'DriverAgeBin' = cut(db$DriverAge, breaks=quantile(db$DriverAge, seq(0, 1, 0.1)), include.lowest = TRUE),
                   'DensityBin' = cut(db$Density, breaks=quantile(db$Density, seq(0, 1, 0.1)), include.lowest = TRUE))
temp <- cbind(temp, 'ClaimNb'=db$ClaimNb, 'Exposure'=db$Exposure)
```

```{r, fig.align='center', tidy=TRUE}
for (varGraph in whichCont){
  print(plotCatFunc(temp, paste0(varGraph, "Bin"), axisScale=scalingValues[[varGraph]], dodge=(varGraph=='Density')))
}
```

# Create working datasets

As we're dealing with ML models, a classical approach consists in splitting the dataset into two parts, namely:

* A **training set** which will be heavily used to train the different models and will serve for model selection.
* A **testing set** which will be hold off and used at the end to assess generalization performances.

```{r, tidy=TRUE}
db$PolicyID <- NULL
db$ClaimFreq <- db$ClaimNb/db$Exposure

set.seed(101)
trainObs <- caret::createDataPartition(db$ClaimNb, times = 1, p = 0.8, list = FALSE)
trainSet <- db[sample(trainObs, nrow(trainObs)),]
testSet <- db[-trainObs,]

(nrow(testSet) + nrow(trainSet) == nrow(db))
sum(trainSet$ClaimNb)/sum(trainSet$Exposure)
sum(testSet$ClaimNb)/sum(testSet$Exposure)
```

# Challenger model: Classification And Regression Trees (CART)

As `BT` is based on a succession of trees built thanks to `rpart` package, it might be interesting to look at the individual performances.
In particular, the latter package allows to model Poisson distributed response variable.
Let us define the model formula in this specific context and fit the first tree.

```{r, tidy=TRUE}
formNb <- as.formula("ClaimNb ~ offset(log(Exposure)) + Brand + CarAge + Density + DriverAge + Gas + Power + Region")

tree0 <- rpart(formula = formNb,
               data = trainSet,
               method = "poisson")
summary(tree0)
```

It appears that the resulting tree has only node (root node) and no further splits. This can be explained by the **complexity parameter** (`cp`) which is too high.
Let's reduce this parameter to 0 (i.e. no penalization on the tree's size) and impose a maximum depth of 3 as well as a minimum number of observations within leaves of 2000.

```{r, tidy=TRUE}
tree1 <- rpart(formula=formNb,
               data = trainSet,
               method = "poisson",
               control = rpart.control(cp = 0, maxdepth = 3, minbucket = 2000))
summary(tree1)
```

While the summary is interesting, it might be easier to interpret the tree by plotting it.

```{r, fig.align='center', tidy=TRUE}
rpart.plot::rpart.plot(tree1)
```

If the tree is too large, we will probably have some overfitting. To prevent overfitting, we can play with the complexity parameter. 
A good approach is to compute the whole tree, without any penalty (i.e. complexity parameter is set to 0) and afterwards **prune** the tree.

```{r, fig.align='center', tidy=TRUE}
tree2 <- rpart(formula=formNb,
               data = trainSet,
               method = "poisson",
               control = rpart.control(cp = 0))
rpart.plot::rpart.plot(tree2)
```

For example, we now prune the tree with a complexity parameter of 0.005.

```{r, fig.align='center', tidy=TRUE}
rpart.plot::rpart.plot(prune(tree2, cp=0.005))
```

... It however does not correspond to the optimal tree.
This optimal sub-tree can be found via cross-validation. Please note that 10-folds cross-validation is performed by default, thanks to the `xval` control parameter.
We can then have a look at the **complexity parameter table**.

```{r, fig.align='center', tidy=TRUE}
cpTableDF <- as.data.frame(tree2$cptable)
head(cpTableDF, 50) #printcp(tree2)
```

From this table, we can plot the errors and extract the optimal complexity parameter that will further be used for pruning.

```{r, fig.align='center', tidy=TRUE}
cpOpt <- cpTableDF[which.min(cpTableDF$xerror), "CP"]

ggplot(cpTableDF, aes(x=CP, y=xerror)) + geom_line() + geom_vline(xintercept = cpOpt, color = 'red')
cpOpt
```

We can finally prune with this parameter to find the optimal tree.

```{r, tidy=TRUE, fig.align='center'}
treeOpt <- prune(tree2, cp=cpOpt)
rpart.plot::rpart.plot(treeOpt)
```

# Boosting Tree (BT)

The basic idea behind this algorithm consists in building tree to explain the remaining error, using all the past iterations. It differs from the Gradient Boosting Methods as we're here boosting the residuals rather than the pseudo-residuals, using the defined underlying distribution rather than a gaussian approach.


In this particular package, the **offset** is not implemented. That being said, in a Tweedie log-link framework, the following statements are equivalent:

* Working with the claim count `ClaimNb` and the `Exposure` in offset.
* Working with the claim frequency `ClaimFreq` and the `Exposure` as weight.

Let us define the model formula that will be heavily used.

```{r, tidy=TRUE}
formFreq <- as.formula("ClaimFreq ~ Brand + CarAge + Density + DriverAge + Gas + Power + Region")
```


## `BT` fit and outputs

We propose to begin this section by looking on a simple example.
We can then discuss the different available package's features.

A first `BT` can be fitted without cross-validation

```{r, tidy=TRUE}
bt0 <- BT(formula = formFreq,
          data = trainSet,
          tweedie.power = 1,
          ABT = FALSE,
          n.iter = 300,
          train.fraction = 0.8,
          interaction.depth = 5,
          shrinkage = 0.01,
          bag.fraction = 0.5,
          colsample.bytree = NULL,
          keep.data = TRUE,
          is.verbose = FALSE,
          cv.folds = 1,
          folds.id = NULL,
          n.cores = 1,
          weights = Exposure,
          seed = 4)
```

One can first have a look at the return object.
Almost all the parameters that have been used during the call are stored.

```{r, tidy=TRUE}
bt0$call
bt0$distribution
bt0$BTParams
bt0$keep.data
bt0$is.verbose
bt0$seed
#bt0$w / bt0$response / bt0$var.name
```

A built-in `print` function is also available. This method prints some of the already presented values.
```{r, tidy=TRUE}
print(bt0)
```

One can have a specific look at the initialization that has been performed via

```{r, tidy=TRUE}
str(bt0$BTInit)
```

If `keep.data=TRUE`, the different databases with the last evaluation are returned

```{r, tidy=TRUE}
str(bt0$BTData)
```

The fitted values (on the score scale) as well as the computed errors across the iterations are available

```{r, tidy=TRUE}
head(bt0$fitted.values, 5)
str(bt0$BTErrors)
```

Finally, each tree built in the expansion are stored within the following object. Each element corresponds to a specific `rparr` object.

```{r, tidy=TRUE}
length(bt0$BTIndivFits)
# First tree in the expansion.
bt0$BTIndivFits[[1]]
bt0$BTIndivFits[[1]]$frame
```

### Optimal iterations number

`BT_perf` function allows the user to determine the best number of iterations that has to be performed. This one also depends on the type of errors that are available/have been computed during training phase.

Depending on the chosen approach, the following methods can be applied to compute the best number of iterations.

* If user wants to use the `validation.error`, the `argmin(BT$BTErrors$validation.error)` will be returned as optimal iteration.
* If user wants to use the `oob.improvement`, the `argmin(-cumsum(BT$BTErrors$oob.improvement))` will be returned as optimal iteration. To be precise, the `oob.improvement` are not used as such but a smoothed version of it.
* If user wants to use the `cv.error`, the `argmin(BT$BTErrors$cv.error)` will be returned as optimal iteration.

We now present the function arguments:

* `BTFit_object`: a `BT` algorithm result.
* `method`: Allows the user to specify the method that has to be applied to compute the best number of iterations. This can be set to `validation`, `OOB` or `cv` depending whether the user wants to use `validation.error`, `oob.improvement` or `cv.error` as previously explained. 
We emphasize that without specifying the `method` argument a best guess approach will be performed.
* `plot.it`, `oobag.curve`, `overlay` and `main`: plot related parameters. If desired, the `BT_perf` function plots the computed errors alongside returning the optimal iteration.

In our specific context, only the OOB improvements and validation errors are available.

```{r, tidy=TRUE, fig.align='center'}
perfbt0_OOB <- BT_perf(bt0, method="OOB", oobag.curve = TRUE)
perfbt0_OOB
```

```{r, tidy=TRUE, fig.align='center'}
perfbt0_val <- BT_perf(bt0, method="validation")
perfbt0_val
```

Using the implemented "best guess" approach

```{r, tidy=TRUE}
perfbt0_BG <- BT_perf(bt0, plot.it = FALSE)
perfbt0_BG
```

### Continue training

It clearly seems that our model does not contain enough trees. In fact, the optimal number of iterations is equal to the model number of iterations, meaning that the minimal error (and the related iteration) should still be found.
It's therefore interesting to continue the training.

This training continuation can be performed thanks to the `BT_more` function. This one has the following arguments:

* `BTFit_object`: an initial `BT` call on which we want to continue the training/perform more iterations.
* `new.n.iter`: number of new boosting/tree iterations to compute. In total, the `BT` object will end up with `n.iter + new.n.iter` iterations.
* `is.verbose`: whether or not the user wants to display algorithm evolution.
* `seed`: optional parameter that allows reproducible example.

It will then return a `BTFit` object (as the `BT` function does) augmented by the new boosting iterations.

We emphasize that the call to this function call only be made if the original `BT` call:

* has no cross-validation;
* has been computed with `keep.data` parameter set to `TRUE`.

```{r, tidy=TRUE}
bt1 <- BT_more(bt0, new.n.iter = 800, seed = 4)
# See parameters and different inputs.
bt1$BTParams$n.iter
```

Do we finally reach an optimum ?

```{r, tidy=TRUE}
perfbt1_OOB <- BT_perf(bt1, method = 'OOB', plot.it = FALSE)
perfbt1_val <- BT_perf(bt1, method = 'validation', plot.it = FALSE)
perfbt1_OOB; perfbt1_val
```

## Cross-validation

We often favor doing cross-validation to find the optimal number of iterations. Let's see the results if a 3-folds cross-validation is performed.

```{r, tidy=TRUE}
bt2 <- BT(formula = formFreq, 
          data = trainSet,
          tweedie.power = 1,
          ABT = FALSE,
          n.iter = 1000,
          train.fraction = 1,
          interaction.depth = 5,
          shrinkage = 0.01,
          bag.fraction = 0.5,
          colsample.bytree = NULL,
          keep.data = TRUE,
          is.verbose = FALSE,
          cv.folds = 3,
          folds.id = NULL,
          n.cores = 3,
          weights = Exposure,
          seed = 4)
```

Different objects are now available within the new `BT` results

```{r, tidy=TRUE}
bt2$cv.folds
str(bt2$folds)
str(bt2$cv.fitted)
str(bt2$BTErrors)
```

We can also find the optimal number of iterations via

```{r, tidy=TRUE, fig.align='center'}
perfbt2_cv <- BT_perf(bt2, method = 'cv')
```

## Hyperparameter Optimization

We only worked with one parameter set up to now. In practice, this set has to be found.
An usual approach consists in performing a grid search and assessing the performances via cross-validation. Please note that using a validation set can also be used, depending on the computation time.

For this presentation, only one extra boosting tree will be fitted.

```{r, tidy=TRUE}
bt3 <- BT(formula = formFreq, 
          data = trainSet,
          tweedie.power = 1,
          ABT = FALSE,
          n.iter = 1000,
          train.fraction = 1,
          interaction.depth = 4,
          shrinkage = 0.01,
          bag.fraction = 0.5,
          colsample.bytree = NULL,
          keep.data = TRUE,
          is.verbose = FALSE,
          cv.folds = 3,
          folds.id = NULL,
          n.cores = 3,
          weights = Exposure,
          seed = 4)
```

We generally select the best model by finding the one with the lowest cross-validation deviance.

```{r, tidy=TRUE}
c(min(bt2$BTErrors$cv.error), min(bt3$BTErrors$cv.error))
btOpt <- bt3
perfbtOpt_cv <- BT_perf(btOpt, method='cv', plot.it=FALSE)
perfbtOpt_cv
```

## Relative influence

Now that the optimal model has been found, one can compute the relative influence. It corresponds to the gain made by splitting over the features.

The `summary` function allows to compute these values and plot.
It is in fact a wrapper for the `BT_relative_influence` which is not intended to be used per end-user.

Up to now, the computation of the relative influence isn't available for the permutation approach. This one should still be developed.

One can then present the function's arguments:

* `object`: a `BTFit` object, i.e. the result of the `BT` call.
* `n.iter`: the number of iterations to use to compute the relative influence. This parameter is often set to the optimal number of iterations. 
By default, all the built trees will be used.
* `method`: the function that has to be called to compute the relative influence. As previously mentioned, only one approach is currently available. This parameter should therefore remains set to its default value.
* `normalize`: if the user wants to normalize the relative influence such that the sum over all normalized relative influence sum up to 100.
* `order_it`: indicates whether the user wants to sort the relative influence or not.
* `cBars` and `plot_it`: relative influence plot related parameters, respectively the number of bars to plot in the barplot and a boolean specifying whether the plot has to be performed or not.

```{r, tidy=TRUE}
summary(btOpt, n.iter = perfbtOpt_cv)
```

## Prediction

Fortunately, once a `BT` object created we can use it to predict on a new database, using the `predict` function. 
To this end, the optimal number of iterations is a desirable input.
We also underline that the model fitted on the whole training set is used.

Here are the function arguments:

* `object`: a `BTFit` object
* `newdata`: the new data set used to compute the predictions.
* `n.iter`: the number of boosting iterations (i.e. the number of trees) used to perform the predictions. Usually, all the iterations (i.e. the trees) up to the best one are considered to build the predictions. 
Please note that this parameter can be a vector. In such a case, a matrix containing the predictions for each element in `n.iter` will be returned.
* `type`: specify if one wants to predict on the 'response' or the 'link' scale. 
* `single.iter`: if set to `TRUE` only the `n.iter` tree will be used to predict (i.e. not all the trees up to `n.iter`).

Please note that if the `keep.data` argument was set to `TRUE` and if the `newdata` is not specified, the prediction will be achieved on the original training set.

```{r, tidy=TRUE}
# Predict (link scale) using all trees up the best iteration OOB/CV.
head(predict(btOpt, n.iter = c(BT_perf(btOpt, method='OOB', plot.it=FALSE), perfbtOpt_cv), type = 'link'), 10) 
# Predict using only the 40th tree.
head(predict(btOpt, n.iter = 40, type = 'response', single.iter = TRUE), 10)
```


# Adaptive Boosting Tree (ABT)

All the functions available on the classical Boosting Tree side are also available in the Adaptive Boosting Tree context.
The only difference lies in the way the number of internal nodes is defined.
For a given `interaction.depth`, ABT will in fact look for the biggest optimal tree having at most `interaction.depth` internal nodes. This idea is basically based on the `rpart` complexity parameter. Differently said, all the trees in the expansion won't necessarily contain `interaction.depth` internal nodes.

By construction, it's interesting to note that the built trees will converge to a single root node.
This can therefore acts as a natural stopping criteria helping to reduce the computation time.

## Hyperparameter Optimization

As we did in the BT side, we'll test two parameters combination and assess their performances via cross-validation.
Let's start by defining the parameters grid.

```{r, tidy=TRUE}
nIterVec <- 1500
interactionDepthVec <- c(4, 5)
shrinkageVec <- 0.01
bagFractionVec <- 0.5

gridSearch <- expand.grid(n.iter = nIterVec,
                          interaction.depth = interactionDepthVec, 
                          shrinkage = shrinkageVec, 
                          bag.fraction = bagFractionVec)
gridSearch
```

We can now loop through all the different scenarios.

```{r, tidy=TRUE}
abtRes_cv <- list()
for (iGrid in seq(1, nrow(gridSearch)))
{
  currABT <- BT(formula = formFreq, 
              data = trainSet,
              tweedie.power = 1,
              ABT = TRUE,
              n.iter = gridSearch[iGrid, "n.iter"],
              train.fraction = 1,
              interaction.depth = gridSearch[iGrid, "interaction.depth"],
              shrinkage = gridSearch[iGrid, "shrinkage"],
              bag.fraction = gridSearch[iGrid, "bag.fraction"],
              colsample.bytree = NULL,
              keep.data = FALSE,
              is.verbose = FALSE,
              cv.folds = 3,
              folds.id = NULL,
              n.cores = 3,
              weights = Exposure,
              seed = 4)
  
  abtRes_cv[[iGrid]] <- currABT
}
```

Check that we've enough iterations and define the best ABT model.

```{r, tidy=TRUE, fig.align='center'}
perfabt1_cv <- BT_perf(abtRes_cv[[1]], method='cv', plot.it=TRUE)
perfabt2_cv <- BT_perf(abtRes_cv[[2]], method='cv', plot.it=TRUE)
```

We can finally define the best ABT model.

```{r, tidy=TRUE}
c(min(abtRes_cv[[1]]$BTErrors$cv.error), min(abtRes_cv[[2]]$BTErrors$cv.error))
abtOpt <- abtRes_cv[[2]]
perfabtOpt_cv <- perfabt2_cv
```

## Miscellaneous

Let's have a look at the resulting trees from BT and ABT expansions.

```{r, tidy=TRUE}
table(sapply(seq(1, perfbtOpt_cv), function(xx){nrow(btOpt$BTIndivFits[[xx]]$frame[btOpt$BTIndivFits[[xx]]$frame$var != "<leaf>",])}))
table(sapply(seq(1, perfabtOpt_cv), function(xx){nrow(abtOpt$BTIndivFits[[xx]]$frame[abtOpt$BTIndivFits[[xx]]$frame$var != "<leaf>",])}))
```


# Challenger model: Gradient Boosting Models (GBM)

To build a GBM challenger, we'll use the `gbm3` package.
Obviously, the same approach can be followed to determine the best set of parameters.

We emphasize that `BT` package's design is similar to `gbm3` one.
A lot of functions will therefore act in a similar fashion. We refer the interested reader to its [documentation](https://github.com/gbm-developers/gbm3).

For this example purpose, let us consider the same grid search as previously defined and build the cross-validation.

```{r, tidy=TRUE}
gbmRes_cv <- list()
for (iGrid in seq(1, nrow(gridSearch)))
{
  set.seed(4)

  currGBM <- gbm(
    formula = formNb,
    data = trainSet,
    distribution = "poisson",
    cv.folds = 3,
    train.fraction = 1,
    n.trees = gridSearch[iGrid, "n.iter"],
    interaction.depth = gridSearch[iGrid, "interaction.depth"],
    shrinkage = gridSearch[iGrid, "shrinkage"],
    bag.fraction = gridSearch[iGrid, "bag.fraction"],
    n.minobsinnode = 2,
    par.details = gbmParallel(num_threads = 3)
  )
  
  gbmRes_cv[[iGrid]] <- currGBM
}
```

Check that we've enough iterations and define the best GBM model.

```{r, tidy=TRUE, fig.align='center'}
perfgbm1_cv <- gbm3::gbm.perf(gbmRes_cv[[1]], method='cv', plot.it=TRUE)
perfgbm2_cv <- gbm3::gbm.perf(gbmRes_cv[[2]], method='cv', plot.it=TRUE)
```

We can finally define the best GBM model.

```{r, tidy=TRUE}
c(min(gbmRes_cv[[1]]$cv_error), min(gbmRes_cv[[2]]$cv_error))
gbmOpt <- gbmRes_cv[[1]]
perfgbmOpt_cv <- perfgbm1_cv
```

# Models comparison

Once the optimal competing models have been defined, one can assess their generalization performances (i.e. on the test set).
To do so, multiple criteria might be used, such as:

* Deviance
* Lift curves
* Concordance measures
* ...

**Please note that usually only 1 model is retained beforehand - The test set is not used for model selection. Our specific example remains a case-study!**

Let's start by computing the different model predictions on the test set.

```{r, tidy=TRUE, message=FALSE}
treePredTest <- predict(treeOpt, testSet, type = 'vector')*testSet$Exposure
btPredTest <- predict(btOpt, newdata = testSet, n.iter = perfbtOpt_cv, type = 'response')*testSet$Exposure
abtPredTest <- predict(abtOpt, newdata = testSet, n.iter = perfabtOpt_cv, type = 'response')*testSet$Exposure
gbmPredTest <- predict(gbmOpt, newdata = testSet, n.trees = perfgbmOpt_cv, type = 'response')*testSet$Exposure
```

## Deviance

The deviance is defined as 2 times the log-likelihood ratio of the saturated model compared to the reduced (fitted) one.
In other words, it measures the gap between the optimal model and the current one.

```{r, tidy=TRUE}
devPoisson <- function(obs, pred){
  2*(sum(dpois(x=obs, lambda=obs, log=TRUE)) - sum(dpois(x=obs, lambda=pred, log=TRUE)))
}
```

We can now assess the deviance of our different models.

```{r, tidy=TRUE}
devPoisson(testSet$ClaimNb, treePredTest)
devPoisson(testSet$ClaimNb, btPredTest)
devPoisson(testSet$ClaimNb, abtPredTest)
devPoisson(testSet$ClaimNb, gbmPredTest)
```

## Lift curves

The simple lift chart consists in sorting the database based on the predicted values. The database is then equally bucketed (let say 10 bins).
Within each bucket, the average prediction is finally compared to the average observation.
This can be achieved thanks to the following function:

```{r, tidy=TRUE}
computeLift <- function (obs, pred, exposure=NULL, n.buckets = 10)
{
  lift <- cbind(pred, obs, exposure)
  lift <- lift[order(lift[, "pred"]), ]
  
  if (!is.null(exposure)){
    totExp <- sum(lift[, "exposure"])
    expGroup <- totExp/n.buckets * seq(0, n.buckets)
    cumExp <- cumsum(lift[, "exposure"])
    buckets <- cut(cumExp, expGroup, labels=FALSE, include.lowest = TRUE)
  }else{
    totExp <- nrow(lift)
    expGroup <- totExp/n.buckets * seq(0, n.buckets)
    cumExp <- seq_along(lift[, "obs"])
    buckets <- cut(cumExp, expGroup, labels=FALSE, include.lowest = TRUE)
  }
  
  liftValues <- aggregate(lift[, c("obs", "pred")], by = list(buckets), mean)
  colnames(liftValues)[1] <- "Decile"
  
  if (!is.null(exposure)) liftValues$exposure <- aggregate(lift[, "exposure"], by = list(buckets), sum)[,2]
    
  liftPlot <- reshape2::melt(liftValues, id.vars = c("Decile", "exposure"))
  
  print(ggplot(liftPlot) +
    geom_bar(aes(x=as.factor(Decile), y = exposure), stat="identity", alpha=.5) +
    geom_line(aes(x=Decile, y = value * 15 * max(exposure), linetype=variable)) +
    scale_y_continuous("Exposure", sec.axis = sec_axis(~./(15*max(liftPlot$exposure)), name = "Average")) + 
    theme_minimal() +
    xlab("Decile")
  )
}
```

We can now plot the lift curves for all competing models.

```{r, tidy=TRUE, fig.align='center'}
computeLift(testSet$ClaimNb, treePredTest, exposure = testSet$Exposure)
computeLift(testSet$ClaimNb, btPredTest, exposure = testSet$Exposure)
computeLift(testSet$ClaimNb, abtPredTest, exposure = testSet$Exposure)
computeLift(testSet$ClaimNb, gbmPredTest, exposure = testSet$Exposure)
```










